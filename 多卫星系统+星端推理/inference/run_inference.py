2
import sys
import os
import torch
import time
import argparse
import csv
from glob import glob
import re
import random
import json
import pandas as pd
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
from PIL import Image
import numpy as np
import matplotlib.pyplot as plt
from train_model import DeepLabWithSimFeature  # å¯¼å…¥æˆ‘ä»¬çš„è‡ªå®šä¹‰æ¨¡å‹
# Excelæ”¯æŒ
try:
    import openpyxl
    from openpyxl import Workbook
except ImportError:
    openpyxl = None

def load_image(image_path):
    img = Image.open(image_path).convert('RGB')
    img = img.resize((256, 256))
    img = np.array(img) / 255.0
    img = torch.tensor(img, dtype=torch.float32).permute(2, 0, 1).unsqueeze(0)
    
    # åº”ç”¨ä¸è®­ç»ƒæ—¶ç›¸åŒçš„å½’ä¸€åŒ–
    mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)
    std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)
    img = (img - mean) / std
    
    return img

def load_sim_features(sim_feature_csv="data/sim_features.csv"):
    """åŠ è½½ä»¿çœŸç‰¹å¾æ•°æ®"""
    try:
        sim_features_df = pd.read_csv(sim_feature_csv)
        print(f"CSVæ–‡ä»¶å½¢çŠ¶: {sim_features_df.shape}")
        print(f"CSVåˆ—å: {sim_features_df.columns.tolist()}")
        
        # æŸ¥æ‰¾æ–‡ä»¶ååˆ—
        filename_col = None
        possible_filename_cols = ['img_path', 'filename', 'Filename', 'file_name', 'File', 'image', 'Image', 'name', 'Name']
        
        for col in possible_filename_cols:
            if col in sim_features_df.columns:
                filename_col = col
                break
        
        if filename_col is None:
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ–‡ä»¶ååˆ—ï¼Œä½¿ç”¨ç¬¬ä¸€åˆ—ä½œä¸ºæ–‡ä»¶å
            filename_col = sim_features_df.columns[0]
            print(f"æœªæ‰¾åˆ°æ ‡å‡†æ–‡ä»¶ååˆ—ï¼Œä½¿ç”¨ç¬¬ä¸€åˆ— '{filename_col}' ä½œä¸ºæ–‡ä»¶å")
        
        # åˆ›å»ºæ–‡ä»¶ååˆ°ç‰¹å¾çš„æ˜ å°„
        sim_feature_dict = {}
        # åªé€‰æ‹©æ•°å€¼å‹ç‰¹å¾åˆ—ï¼Œæ’é™¤å­—ç¬¦ä¸²åˆ—
        numeric_cols = []
        for col in sim_features_df.columns:
            if col != filename_col:
                # æ£€æŸ¥åˆ—æ˜¯å¦ä¸ºæ•°å€¼å‹
                try:
                    pd.to_numeric(sim_features_df[col], errors='raise')
                    numeric_cols.append(col)
                except (ValueError, TypeError):
                    print(f"è·³è¿‡éæ•°å€¼åˆ—: {col} (åŒ…å«å­—ç¬¦ä¸²å€¼)")
        
        print(f"ä½¿ç”¨æ•°å€¼ç‰¹å¾åˆ—: {numeric_cols}")
        
        for _, row in sim_features_df.iterrows():
            filename = str(row[filename_col])
            try:
                features = row[numeric_cols].values.astype(np.float32)
                sim_feature_dict[filename] = features
            except Exception as e:
                print(f"è·³è¿‡è¡Œ {filename}: {e}")
                continue
        
        print(f"âœ… æˆåŠŸåŠ è½½ {len(sim_feature_dict)} ä¸ªä»¿çœŸç‰¹å¾")
        print(f"ğŸ“Š ç‰¹å¾ç»´åº¦: {len(numeric_cols)}")
        print(f"ğŸ“‹ ç‰¹å¾åˆ—: {numeric_cols}")
        print(f"ğŸ” ç‰¹å¾ç»Ÿè®¡:")
        print(f"   - æ•°å€¼åˆ—æ•°: {len(numeric_cols)}")
        print(f"   - å­—ç¬¦ä¸²åˆ—æ•°: {len(sim_features_df.columns) - len(numeric_cols) - 1}")
        print(f"   - æ€»æ ·æœ¬æ•°: {len(sim_feature_dict)}")
        return sim_feature_dict
        
    except Exception as e:
        print(f"åŠ è½½ä»¿çœŸç‰¹å¾å¤±è´¥: {e}")
        print("è¯·æ£€æŸ¥CSVæ–‡ä»¶æ ¼å¼æ˜¯å¦æ­£ç¡®")
        return {}

def get_sim_features_for_image(image_path, sim_feature_dict):
    """æ ¹æ®å›¾åƒè·¯å¾„è·å–å¯¹åº”çš„ä»¿çœŸç‰¹å¾"""
    # æå–æ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰
    filename = os.path.splitext(os.path.basename(image_path))[0]
    
    # å°è¯•å¤šç§å¯èƒ½çš„åŒ¹é…æ–¹å¼
    possible_keys = [
        filename,  # å®Œæ•´æ–‡ä»¶å
        filename.replace('_post_disaster', '').replace('_pre_disaster', ''),  # åŸºç¡€æ–‡ä»¶å
        filename + '_post_disaster',
        filename + '_pre_disaster'
    ]
    
    # é¦–å…ˆå°è¯•ç›´æ¥åŒ¹é…
    for key in possible_keys:
        if key in sim_feature_dict:
            features = sim_feature_dict[key]
            # å½’ä¸€åŒ–ç‰¹å¾
            features = (features - np.mean(features)) / np.std(features)
            return torch.tensor(features, dtype=torch.float32)
    
    # å¦‚æœç›´æ¥åŒ¹é…å¤±è´¥ï¼Œå°è¯•åœ¨è·¯å¾„ä¸­æŸ¥æ‰¾
    for csv_key in sim_feature_dict.keys():
        # æ£€æŸ¥CSVé”®æ˜¯å¦åŒ…å«æˆ‘ä»¬çš„æ–‡ä»¶å
        if filename in csv_key or filename.replace('_post_disaster', '').replace('_pre_disaster', '') in csv_key:
            features = sim_feature_dict[csv_key]
            # å½’ä¸€åŒ–ç‰¹å¾
            features = (features - np.mean(features)) / np.std(features)
            print(f"æ‰¾åˆ°åŒ¹é…: {filename} -> {csv_key}")
            return torch.tensor(features, dtype=torch.float32)
    
    # å¦‚æœè¿˜æ˜¯æ‰¾ä¸åˆ°ï¼Œå°è¯•æ¨¡ç³ŠåŒ¹é…
    for csv_key in sim_feature_dict.keys():
        # æå–CSVé”®ä¸­çš„æ–‡ä»¶åéƒ¨åˆ†
        csv_filename = os.path.basename(csv_key)
        csv_filename = os.path.splitext(csv_filename)[0]
        
        if filename == csv_filename or filename.replace('_post_disaster', '').replace('_pre_disaster', '') == csv_filename.replace('_post_disaster', '').replace('_pre_disaster', ''):
            features = sim_feature_dict[csv_key]
            # å½’ä¸€åŒ–ç‰¹å¾
            features = (features - np.mean(features)) / np.std(features)
            print(f"æ¨¡ç³ŠåŒ¹é…æˆåŠŸ: {filename} -> {csv_key}")
            return torch.tensor(features, dtype=torch.float32)
    
    # å¦‚æœæ‰¾ä¸åˆ°å¯¹åº”ç‰¹å¾ï¼Œè¿”å›é›¶å‘é‡
    print(f"è­¦å‘Š: æœªæ‰¾åˆ°å›¾åƒ {filename} å¯¹åº”çš„ä»¿çœŸç‰¹å¾ï¼Œä½¿ç”¨é›¶å‘é‡")
    print(f"å¯ç”¨çš„CSVé”®ç¤ºä¾‹: {list(sim_feature_dict.keys())[:3]}")  # æ˜¾ç¤ºå‰3ä¸ªé”®ä½œä¸ºç¤ºä¾‹
    return torch.zeros(11, dtype=torch.float32)

def load_deeplab_model(model_path, device):
    # ä½¿ç”¨æˆ‘ä»¬çš„è‡ªå®šä¹‰å¤šæ¨¡æ€æ¨¡å‹
    model = DeepLabWithSimFeature(
        in_channels=3,
        num_classes=1,
        sim_feat_dim=11
    )
    
    # æ™ºèƒ½åŠ è½½æ¨¡å‹ - æ”¯æŒæ£€æŸ¥ç‚¹æ ¼å¼å’Œçº¯æƒé‡æ ¼å¼
    checkpoint = torch.load(model_path, map_location=device)
    
    if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:
        # æ£€æŸ¥ç‚¹æ ¼å¼
        print("æ£€æµ‹åˆ°æ£€æŸ¥ç‚¹æ ¼å¼ï¼ŒåŠ è½½æ¨¡å‹çŠ¶æ€å­—å…¸...")
        state_dict = checkpoint['model_state_dict']
    else:
        # çº¯æƒé‡æ ¼å¼
        print("æ£€æµ‹åˆ°çº¯æƒé‡æ ¼å¼ï¼Œç›´æ¥åŠ è½½...")
        state_dict = checkpoint
    
    # å¤„ç†æ¨¡å‹ç»“æ„å…¼å®¹æ€§é—®é¢˜
    print("æ£€æŸ¥æ¨¡å‹ç»“æ„å…¼å®¹æ€§...")
    model_state_dict = model.state_dict()
    
    # å¤„ç†sim_fcå±‚çš„é”®åå˜åŒ–ï¼ˆä»sim_fc.2åˆ°sim_fc.3ï¼‰
    updated_state_dict = {}
    for key, value in state_dict.items():
        if key.startswith('sim_fc.2.') and key not in model_state_dict:
            # å°†sim_fc.2.weight -> sim_fc.3.weight
            new_key = key.replace('sim_fc.2.', 'sim_fc.3.')
            if new_key in model_state_dict:
                updated_state_dict[new_key] = value
                print(f"é”®åæ˜ å°„: {key} -> {new_key}")
            else:
                print(f"è­¦å‘Š: æ— æ³•æ˜ å°„é”® {key}")
        else:
            updated_state_dict[key] = value
    
    # åŠ è½½å…¼å®¹åçš„çŠ¶æ€å­—å…¸
    try:
        model.load_state_dict(updated_state_dict, strict=False)
        print("æ¨¡å‹åŠ è½½æˆåŠŸï¼ˆä½¿ç”¨éä¸¥æ ¼æ¨¡å¼ï¼‰")
    except Exception as e:
        print(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return None
    
    model.eval()
    model.to(device)
    return model

def load_quantized_model(model_path, device):
    model = torch.jit.load(model_path, map_location=device)
    model.eval()
    model.to(device)
    return model

def infer_and_time(model, img, model_type, sim_feats=None, repetitions=20):
    # å¦‚æœæ²¡æœ‰æä¾›sim_featsï¼Œä½¿ç”¨é›¶å‘é‡ä½œä¸ºé»˜è®¤å€¼
    if sim_feats is None:
        batch_size = img.shape[0]
        sim_feats = torch.zeros(batch_size, 11, device=img.device)
    else:
        # ç¡®ä¿sim_featsåœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Š
        sim_feats = sim_feats.to(img.device)
        if sim_feats.dim() == 1:
            sim_feats = sim_feats.unsqueeze(0)  # [11] -> [1, 11]
    
    # é¢„çƒ­
    with torch.no_grad():
        _ = model(img, sim_feats)
    
    times = []
    with torch.no_grad():
        for _ in range(repetitions):
            start = time.perf_counter()
            pred = model(img, sim_feats)
            end = time.perf_counter()
            times.append((end - start) * 1000)  # ms
    
    avg_time = sum(times) / len(times)
    min_time = min(times)
    max_time = max(times)
    
    # å¤„ç†é¢„æµ‹è¾“å‡º
    if isinstance(pred, (tuple, list)):
        pred = pred[0]
    
    # æ£€æŸ¥åŸå§‹è¾“å‡ºèŒƒå›´
    raw_pred = pred.detach().cpu()
    print(f"ğŸ” æ¨¡å‹åŸå§‹è¾“å‡º:")
    print(f"  åŸå§‹èŒƒå›´: [{raw_pred.min().item():.3f}, {raw_pred.max().item():.3f}]")
    print(f"  åŸå§‹å‡å€¼: {raw_pred.mean().item():.3f}")
    print(f"  åŸå§‹æ ‡å‡†å·®: {raw_pred.std().item():.3f}")
    
    # ç¡®ä¿è¾“å‡ºç»´åº¦æ­£ç¡®å¹¶åº”ç”¨sigmoid
    if pred.dim() == 4 and pred.shape[1] == 1:
        pred_mask = torch.sigmoid(pred).cpu().numpy()[0, 0]
    else:
        pred_mask = torch.sigmoid(pred).cpu().numpy()[0]
    
    return avg_time, min_time, max_time, pred_mask, sim_feats

def main():
    parser = argparse.ArgumentParser(description='Segmentation Model Inference')
    parser.add_argument('--model_type', type=str, default='original', choices=['original', 'quantized'],
                        help='é€‰æ‹©åŠ è½½åŸå§‹æ¨¡å‹è¿˜æ˜¯é‡åŒ–æ¨¡å‹')
    parser.add_argument('--img_path', type=str, default='data/combined_dataset/images/tier3/',
                        help='è¾“å…¥å›¾ç‰‡è·¯å¾„æˆ–å›¾ç‰‡æ–‡ä»¶å¤¹ï¼ˆæ”¯æŒ*.png,*.jpg,*.jpegï¼‰')
    parser.add_argument('--model_path', type=str, default=None,
                        help='æ¨¡å‹æƒé‡è·¯å¾„ï¼ˆå¯é€‰ï¼‰')
    parser.add_argument('--csv_path', type=str, default='inference/perf_report.csv',
                        help='æ¨ç†æ€§èƒ½è¡¨æ ¼è¾“å‡ºè·¯å¾„ï¼ˆæ”¯æŒ.csvæˆ–.xlsxï¼Œè‡ªåŠ¨ç”Ÿæˆå¦ä¸€ç§æ ¼å¼ï¼‰')
    parser.add_argument('--no_vis', action='store_true', help='ä¸æ˜¾ç¤ºå¯è§†åŒ–çª—å£')
    parser.add_argument('--sim_feature_csv', type=str, default='data/sim_features.csv',
                        help='ä»¿çœŸç‰¹å¾CSVæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--joint_inference', action='store_true', 
                        help='å¯ç”¨è”åˆæ¨ç†ï¼ˆä½¿ç”¨çœŸå®çš„ä»¿çœŸç‰¹å¾ï¼‰')
    args = parser.parse_args()

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    
    # ç”¨æˆ·æ‰‹åŠ¨é€‰æ‹©æ¨ç†æ¨¡å¼
    print("\n" + "="*50)
    print("æ¨ç†ç±»å‹é€‰æ‹©")
    print("="*50)
    print("1 - è”åˆæ¨ç†ï¼ˆå›¾åƒ + ä»¿çœŸç‰¹å¾ï¼‰")
    print("2 - æ ‡å‡†æ¨ç†ï¼ˆä»…å›¾åƒï¼Œé›¶å‘é‡ç‰¹å¾ï¼‰")
    print("="*50)
    
    while True:
        try:
            inference_type = input("è¯·é€‰æ‹©æ¨ç†ç±»å‹ï¼ˆ1æˆ–2ï¼‰ï¼š").strip()
            if inference_type == '1':
                use_joint_inference = True
                print("âœ… é€‰æ‹©è”åˆæ¨ç†æ¨¡å¼ï¼ˆå›¾åƒ + ä»¿çœŸç‰¹å¾ï¼‰")
                break
            elif inference_type == '2':
                use_joint_inference = False
                print("âœ… é€‰æ‹©æ ‡å‡†æ¨ç†æ¨¡å¼ï¼ˆä»…å›¾åƒï¼Œé›¶å‘é‡ç‰¹å¾ï¼‰")
                break
            else:
                print("è¾“å…¥æ— æ•ˆï¼Œè¯·è¾“å…¥1æˆ–2")
        except KeyboardInterrupt:
            print("\nç”¨æˆ·å–æ¶ˆæ“ä½œ")
            return
        except Exception as e:
            print(f"è¾“å…¥é”™è¯¯: {e}ï¼Œè¯·é‡æ–°è¾“å…¥")
    
    # åŠ è½½ä»¿çœŸç‰¹å¾ï¼ˆå¦‚æœé€‰æ‹©è”åˆæ¨ç†ï¼‰
    sim_feature_dict = {}
    if use_joint_inference:
        print("\n" + "="*50)
        print("ä»¿çœŸç‰¹å¾ç±»å‹é€‰æ‹©")
        print("="*50)
        print("1 - ä½¿ç”¨çœŸå®ä»¿çœŸç‰¹å¾ï¼ˆä»CSVæ–‡ä»¶åŠ è½½ï¼‰")
        print("2 - ä½¿ç”¨é›¶å‘é‡ç‰¹å¾ï¼ˆé»˜è®¤ï¼‰")
        print("="*50)
        
        while True:
            try:
                feature_type = input("è¯·é€‰æ‹©ç‰¹å¾ç±»å‹ï¼ˆ1æˆ–2ï¼‰ï¼š").strip()
                if feature_type == '1':
                    use_real_features = True
                    print("âœ… é€‰æ‹©çœŸå®ä»¿çœŸç‰¹å¾ï¼ˆä»CSVæ–‡ä»¶åŠ è½½ï¼‰")
                    break
                elif feature_type == '2':
                    use_real_features = False
                    print("âœ… é€‰æ‹©é›¶å‘é‡ç‰¹å¾ï¼ˆé»˜è®¤ï¼‰")
                    break
                else:
                    print("è¾“å…¥æ— æ•ˆï¼Œè¯·è¾“å…¥1æˆ–2")
            except KeyboardInterrupt:
                print("\nç”¨æˆ·å–æ¶ˆæ“ä½œ")
                return
            except Exception as e:
                print(f"è¾“å…¥é”™è¯¯: {e}ï¼Œè¯·é‡æ–°è¾“å…¥")
        
        if use_real_features:
            print("ğŸ”„ æ­£åœ¨åŠ è½½ä»¿çœŸç‰¹å¾...")
            sim_feature_dict = load_sim_features(args.sim_feature_csv)
            if not sim_feature_dict:
                print("âš ï¸ è­¦å‘Š: ä»¿çœŸç‰¹å¾åŠ è½½å¤±è´¥ï¼Œå°†ä½¿ç”¨é›¶å‘é‡è¿›è¡Œæ¨ç†")
                use_real_features = False
        else:
            print("ğŸ“Š ä½¿ç”¨é›¶å‘é‡ç‰¹å¾è¿›è¡Œè”åˆæ¨ç†")
    else:
        use_real_features = False
        print("ğŸ“Š æ ‡å‡†æ¨ç†æ¨¡å¼ï¼Œä½¿ç”¨é›¶å‘é‡ç‰¹å¾")
    if args.model_type == 'original':
        model_path = args.model_path or "models/best_multimodal_patch_model.pth"
        model = load_deeplab_model(model_path, device)
        if model is None:
            print("æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œé€€å‡ºç¨‹åº")
            return
    else:
        model_path = args.model_path or "models/quantized_seg_model_stage3.pt"
        model = load_quantized_model(model_path, device)

    # æ”¯æŒå•å¼ å›¾ç‰‡æˆ–æ–‡ä»¶å¤¹æ‰¹é‡æ¨ç†
    if os.path.isdir(args.img_path):
        img_files = sorted(glob(os.path.join(args.img_path, '*.png')) + glob(os.path.join(args.img_path, '*.jpg')) + glob(os.path.join(args.img_path, '*.jpeg')))
    else:
        img_files = [args.img_path]

    # ç”¨æˆ·æ‰‹åŠ¨é€‰æ‹©æ¨ç†æ¨¡å¼
    print("\n" + "="*50)
    print("æ¨ç†æ¨¡å¼é€‰æ‹©")
    print("="*50)
    print("1 - æ‰¹é‡æ¨ç†æ•´ä¸ªæ–‡ä»¶å¤¹")
    print("2 - éšæœºæ¨ç†æ–‡ä»¶å¤¹ä¸­çš„ä¸€å¼ å›¾ç‰‡")
    print("3 - æ¨ç†å•å¼ æŒ‡å®šå›¾ç‰‡")
    print("="*50)
    
    while True:
        try:
            mode_input = input("è¯·è¾“å…¥é€‰é¡¹æ•°å­—ï¼ˆ1ã€2æˆ–3ï¼‰ï¼š").strip()
            if mode_input == '1':
                mode = 'all'
                print(f"âœ… é€‰æ‹©æ‰¹é‡æ¨ç†æ¨¡å¼ï¼Œå°†å¤„ç† {len(img_files)} å¼ å›¾ç‰‡")
                break
            elif mode_input == '2':
                if len(img_files) > 1:
                    mode = 'random'
                    selected_img = random.choice(img_files)
                    img_files = [selected_img]
                    print(f"âœ… é€‰æ‹©éšæœºæ¨ç†æ¨¡å¼ï¼Œéšæœºé€‰æ‹©å›¾ç‰‡: {os.path.basename(selected_img)}")
                else:
                    mode = 'single'
                    print("âœ… ä»…æœ‰ä¸€å¼ å›¾ç‰‡ï¼Œè‡ªåŠ¨é€‰æ‹©å•å¼ æ¨ç†æ¨¡å¼")
                break
            elif mode_input == '3':
                mode = 'single'
                print("âœ… é€‰æ‹©å•å¼ æ¨ç†æ¨¡å¼")
                break
            else:
                print("è¾“å…¥æ— æ•ˆï¼Œè¯·è¾“å…¥1ã€2æˆ–3")
        except KeyboardInterrupt:
            print("\nç”¨æˆ·å–æ¶ˆæ“ä½œ")
            return
        except Exception as e:
            print(f"è¾“å…¥é”™è¯¯: {e}ï¼Œè¯·é‡æ–°è¾“å…¥")

    # ç»Ÿä¸€è¾“å‡ºä¸¤ä¸ªæ–‡ä»¶å
    base_path, ext = os.path.splitext(args.csv_path)
    csv_path = base_path + '.csv'
    xlsx_path = base_path + '.xlsx'
    os.makedirs(os.path.dirname(csv_path), exist_ok=True)
    header = ['å›¾ç‰‡å', 'æ¨¡å‹ç±»å‹', 'æ¨ç†æ¨¡å¼', 'å¹³å‡æ—¶å»¶(ms)', 'æœ€å°æ—¶å»¶(ms)', 'æœ€å¤§æ—¶å»¶(ms)', 'ä»¿çœŸç‰¹å¾çŠ¶æ€']
    all_rows = []
    all_avg, all_min, all_max = [], [], []
    for img_path in img_files:
        img = load_image(img_path).to(device)
        
        # è·å–å¯¹åº”çš„ä»¿çœŸç‰¹å¾
        sim_feats = None
        sim_feat_status = "é›¶å‘é‡"
        
        if use_joint_inference:
            if use_real_features and sim_feature_dict:
                sim_feats = get_sim_features_for_image(img_path, sim_feature_dict)
                if sim_feats.sum() != 0:
                    sim_feat_status = "çœŸå®ç‰¹å¾"
                else:
                    sim_feat_status = "é›¶å‘é‡(æœªæ‰¾åˆ°)"
            else:
                # è”åˆæ¨ç†ä½†ä½¿ç”¨é›¶å‘é‡ç‰¹å¾
                sim_feat_status = "é›¶å‘é‡(è”åˆæ¨ç†)"
        else:
            # æ ‡å‡†æ¨ç†ï¼Œä½¿ç”¨é›¶å‘é‡ç‰¹å¾
            sim_feat_status = "é›¶å‘é‡(æ ‡å‡†æ¨ç†)"
        
        avg_time, min_time, max_time, pred_mask, used_sim_feats = infer_and_time(
            model, img, args.model_type, sim_feats
        )
        
        inference_mode = "è”åˆæ¨ç†" if use_joint_inference else "æ ‡å‡†æ¨ç†"
        row = [
            os.path.basename(img_path), 
            args.model_type, 
            inference_mode,
            f"{avg_time:.2f}", 
            f"{min_time:.2f}", 
            f"{max_time:.2f}",
            sim_feat_status
        ]
        all_rows.append(row)
        all_avg.append(avg_time)
        all_min.append(min_time)
        all_max.append(max_time)
        
        print(f"\n{'='*60}")
        print(f"ğŸ“¸ å›¾åƒä¿¡æ¯:")
        print(f"  æ–‡ä»¶å: {os.path.basename(img_path)}")
        print(f"  å®Œæ•´è·¯å¾„: {img_path}")
        print(f"  å›¾åƒå°ºå¯¸: {img.shape[2]}x{img.shape[3]} (CxHxW)")
        
        print(f"\nğŸ¤– æ¨ç†é…ç½®:")
        print(f"  æ¨¡å‹ç±»å‹: {args.model_type}")
        print(f"  æ¨ç†æ¨¡å¼: {inference_mode}")
        print(f"  ç‰¹å¾çŠ¶æ€: {sim_feat_status}")
        print(f"  è®¾å¤‡: {device}")
        
        print(f"\nâš¡ æ€§èƒ½æŒ‡æ ‡:")
        print(f"  å¹³å‡å»¶è¿Ÿ: {avg_time:.2f} ms")
        print(f"  æœ€å°å»¶è¿Ÿ: {min_time:.2f} ms")
        print(f"  æœ€å¤§å»¶è¿Ÿ: {max_time:.2f} ms")
        print(f"  ååé‡: {1000/avg_time:.1f} FPS")
        
        if sim_feats is not None and sim_feats.sum() != 0:
            print(f"\nğŸ“Š ä»¿çœŸç‰¹å¾è¯¦æƒ…:")
            print(f"  ç‰¹å¾ç»´åº¦: {used_sim_feats.shape}")
            print(f"  ç‰¹å¾èŒƒå›´: [{used_sim_feats.min().item():.3f}, {used_sim_feats.max().item():.3f}]")
            print(f"  ç‰¹å¾å‡å€¼: {used_sim_feats.mean().item():.3f}")
            print(f"  ç‰¹å¾æ ‡å‡†å·®: {used_sim_feats.std().item():.3f}")
            print(f"  éé›¶ç‰¹å¾æ•°: {(used_sim_feats != 0).sum().item()}/{used_sim_feats.numel()}")
        elif use_joint_inference and not use_real_features:
            print(f"\nğŸ“Š ä»¿çœŸç‰¹å¾è¯¦æƒ…:")
            print(f"  ä½¿ç”¨é›¶å‘é‡ç‰¹å¾è¿›è¡Œè”åˆæ¨ç†")
            print(f"  ç‰¹å¾ç»´åº¦: {used_sim_feats.shape}")
        
        print(f"\nğŸ¯ é¢„æµ‹ç»“æœ:")
        print(f"  é¢„æµ‹æ©ç å½¢çŠ¶: {pred_mask.shape}")
        print(f"  é¢„æµ‹èŒƒå›´: [{pred_mask.min():.3f}, {pred_mask.max():.3f}]")
        print(f"  é¢„æµ‹å‡å€¼: {pred_mask.mean():.3f}")
        print(f"  é¢„æµ‹æ ‡å‡†å·®: {pred_mask.std():.3f}")
        
        # å¤šé˜ˆå€¼åˆ†æ
        thresholds = [0.1, 0.3, 0.5, 0.7, 0.9]
        print(f"\nğŸ“Š å¤šé˜ˆå€¼åˆ†æ:")
        for threshold in thresholds:
            pred_pixels = (pred_mask > threshold).sum()
            pred_ratio = pred_pixels / pred_mask.size
            print(f"  é˜ˆå€¼ {threshold}: {pred_pixels} åƒç´  ({pred_ratio:.2%})")
        
        # ç½®ä¿¡åº¦åˆ†å¸ƒåˆ†æ
        print(f"\nğŸ“ˆ ç½®ä¿¡åº¦åˆ†å¸ƒ:")
        low_conf = (pred_mask < 0.1).sum() / pred_mask.size
        mid_conf = ((pred_mask >= 0.1) & (pred_mask < 0.5)).sum() / pred_mask.size
        high_conf = (pred_mask >= 0.5).sum() / pred_mask.size
        print(f"  ä½ç½®ä¿¡åº¦ (<0.1): {low_conf:.2%}")
        print(f"  ä¸­ç½®ä¿¡åº¦ (0.1-0.5): {mid_conf:.2%}")
        print(f"  é«˜ç½®ä¿¡åº¦ (â‰¥0.5): {high_conf:.2%}")
        
        # å»ºè®®é˜ˆå€¼
        if pred_mask.max() < 0.5:
            suggested_threshold = pred_mask.max() * 0.8
            print(f"\nâš ï¸ å»ºè®®:")
            print(f"  é¢„æµ‹æœ€å¤§å€¼è¾ƒä½ ({pred_mask.max():.3f})ï¼Œå»ºè®®ä½¿ç”¨æ›´ä½é˜ˆå€¼: {suggested_threshold:.3f}")
            print(f"  ä½¿ç”¨å»ºè®®é˜ˆå€¼: {(pred_mask > suggested_threshold).sum()} åƒç´  ({(pred_mask > suggested_threshold).sum() / pred_mask.size:.2%})")
        
        print(f"{'='*60}")
        
        # å¯è§†åŒ–ï¼ˆä»…å¯¹æœ€åä¸€å¼ å›¾ç‰‡ï¼‰
        if not args.no_vis and img_path == img_files[-1]:
            plt.figure(figsize=(12, 4))
            plt.subplot(1, 3, 1)
            plt.imshow(Image.open(img_path))
            plt.title("Original Image")
            plt.axis('off')
            
            plt.subplot(1, 3, 2)
            plt.imshow(pred_mask, cmap='gray')
            plt.title("Predicted Mask (Raw)")
            plt.axis('off')
            
            plt.subplot(1, 3, 3)
            plt.imshow(pred_mask > 0.5, cmap='gray')
            plt.title("Predicted Mask (Binary)")
            plt.axis('off')
            
            plt.tight_layout()
    plt.show()
    
    # æ±‡æ€»ç»Ÿè®¡
    if len(img_files) > 1:
        inference_mode = "è”åˆæ¨ç†" if use_joint_inference else "æ ‡å‡†æ¨ç†"
        stat_row = ['æ•´ä½“ç»Ÿè®¡', args.model_type, inference_mode, f"{sum(all_avg)/len(all_avg):.2f}", f"{min(all_min):.2f}", f"{max(all_max):.2f}", ""]
        all_rows.append(stat_row)
        
        print(f"\n{'='*80}")
        print(f"ğŸ“ˆ æ•´ä½“æ€§èƒ½ç»Ÿè®¡")
        print(f"{'='*80}")
        print(f"ğŸ“Š å¤„ç†ç»Ÿè®¡:")
        print(f"  æ€»å›¾åƒæ•°: {len(img_files)}")
        print(f"  æ¨ç†æ¨¡å¼: {inference_mode}")
        print(f"  æ¨¡å‹ç±»å‹: {args.model_type}")
        
        print(f"\nâš¡ æ€§èƒ½ç»Ÿè®¡:")
        print(f"  å¹³å‡å»¶è¿Ÿ: {sum(all_avg)/len(all_avg):.2f} ms")
        print(f"  æœ€å°å»¶è¿Ÿ: {min(all_min):.2f} ms")
        print(f"  æœ€å¤§å»¶è¿Ÿ: {max(all_max):.2f} ms")
        print(f"  å»¶è¿Ÿæ ‡å‡†å·®: {((sum((x - sum(all_avg)/len(all_avg))**2 for x in all_avg) / len(all_avg))**0.5):.2f} ms")
        print(f"  å¹³å‡ååé‡: {1000/(sum(all_avg)/len(all_avg)):.1f} FPS")
        
        print(f"\nğŸ’¾ è¾“å‡ºæ–‡ä»¶:")
        print(f"  CSVæŠ¥å‘Š: {csv_path}")
        print(f"  ExcelæŠ¥å‘Š: {xlsx_path}")
        print(f"{'='*80}")
    
    # å†™å…¥CSV
    with open(csv_path, 'w', newline='', encoding='utf-8') as f:
        writer = csv.writer(f)
        writer.writerow(header)
        for row in all_rows:
            writer.writerow(row)
    
    # å†™å…¥Excel
    if openpyxl is None:
        print('è­¦å‘Šï¼šopenpyxlæœªå®‰è£…ï¼Œæ— æ³•è¾“å‡ºExcelæ ¼å¼ã€‚è¯·å…ˆ pip install openpyxl')
    else:
        wb = Workbook()
        ws = wb.active
        ws.append(header)
        for row in all_rows:
            ws.append(row)
        wb.save(xlsx_path)
        print(f"å·²åŒæ—¶è¾“å‡ºCSVå’ŒExcelæ–‡ä»¶ï¼š{csv_path}  {xlsx_path}")

if __name__ == "__main__":
    main()