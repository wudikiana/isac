#!/usr/bin/env python3
"""
æµ‹è¯•æ•°æ®é¢„åŠ è½½åŠŸèƒ½
"""

import torch
import time
import psutil
from train_model import get_multimodal_patch_dataloaders, MemoryCachedDataset, GPUPreloadedDataset

def test_data_loading_speed():
    """æµ‹è¯•ä¸åŒæ•°æ®åŠ è½½æ–¹å¼çš„é€Ÿåº¦"""
    print("="*60)
    print("ğŸš€ æ•°æ®åŠ è½½é€Ÿåº¦æµ‹è¯•")
    print("="*60)
    
    # ç³»ç»Ÿä¿¡æ¯
    total_memory_gb = psutil.virtual_memory().total / (1024**3)
    gpu_memory_gb = torch.cuda.get_device_properties(0).total_memory / (1024**3) if torch.cuda.is_available() else 0
    
    print(f"ç³»ç»Ÿå†…å­˜: {total_memory_gb:.1f} GB")
    print(f"GPUæ˜¾å­˜: {gpu_memory_gb:.1f} GB")
    
    # æµ‹è¯•æ ‡å‡†åŠ è½½
    print("\nğŸ“ æµ‹è¯•æ ‡å‡†æ•°æ®åŠ è½½...")
    start_time = time.time()
    train_loader, val_loader = get_multimodal_patch_dataloaders(
        data_root="D:/patch_dataset",
        sim_feature_csv="data/sim_features.csv",
        batch_size=32,
        num_workers=4,
        damage_boost=2,
        normal_ratio=0.05,
        preload_to_memory=False,
        preload_to_gpu=False
    )
    standard_time = time.time() - start_time
    print(f"æ ‡å‡†åŠ è½½è€—æ—¶: {standard_time:.2f}ç§’")
    
    # æµ‹è¯•å†…å­˜é¢„åŠ è½½
    if total_memory_gb >= 16:
        print("\nğŸ’¾ æµ‹è¯•å†…å­˜é¢„åŠ è½½...")
        start_time = time.time()
        train_loader_mem, val_loader_mem = get_multimodal_patch_dataloaders(
            data_root="D:/patch_dataset",
            sim_feature_csv="data/sim_features.csv",
            batch_size=32,
            num_workers=2,
            damage_boost=2,
            normal_ratio=0.05,
            preload_to_memory=True,
            preload_to_gpu=False
        )
        memory_time = time.time() - start_time
        print(f"å†…å­˜é¢„åŠ è½½è€—æ—¶: {memory_time:.2f}ç§’")
        print(f"é€Ÿåº¦æå‡: {standard_time/memory_time:.2f}x")
    
    # æµ‹è¯•GPUé¢„åŠ è½½
    if gpu_memory_gb >= 8:
        print("\nğŸš€ æµ‹è¯•GPUé¢„åŠ è½½...")
        start_time = time.time()
        train_loader_gpu, val_loader_gpu = get_multimodal_patch_dataloaders(
            data_root="D:/patch_dataset",
            sim_feature_csv="data/sim_features.csv",
            batch_size=32,
            num_workers=0,
            damage_boost=2,
            normal_ratio=0.05,
            preload_to_memory=False,
            preload_to_gpu=True
        )
        gpu_time = time.time() - start_time
        print(f"GPUé¢„åŠ è½½è€—æ—¶: {gpu_time:.2f}ç§’")
        print(f"é€Ÿåº¦æå‡: {standard_time/gpu_time:.2f}x")
    
    # æµ‹è¯•è®­ç»ƒé€Ÿåº¦
    print("\n" + "="*60)
    print("ğŸƒ è®­ç»ƒé€Ÿåº¦æµ‹è¯•")
    print("="*60)
    
    # ä½¿ç”¨æ ‡å‡†åŠ è½½å™¨æµ‹è¯•è®­ç»ƒé€Ÿåº¦
    print("æµ‹è¯•æ ‡å‡†åŠ è½½å™¨çš„è®­ç»ƒé€Ÿåº¦...")
    start_time = time.time()
    batch_count = 0
    for batch_idx, (images, masks, sim_feats) in enumerate(train_loader):
        if batch_idx >= 10:  # åªæµ‹è¯•å‰10ä¸ªbatch
            break
        batch_count += 1
        # æ¨¡æ‹Ÿè®­ç»ƒæ­¥éª¤
        time.sleep(0.01)  # æ¨¡æ‹Ÿè®¡ç®—æ—¶é—´
    
    standard_train_time = time.time() - start_time
    print(f"æ ‡å‡†åŠ è½½è®­ç»ƒ10ä¸ªbatchè€—æ—¶: {standard_train_time:.2f}ç§’")
    print(f"å¹³å‡æ¯batch: {standard_train_time/batch_count:.3f}ç§’")
    
    print("\nâœ… æµ‹è¯•å®Œæˆï¼")

if __name__ == "__main__":
    test_data_loading_speed() 