import torch
import torch.nn as nn
from models.starlite_cnn import create_starlite_model

def test_optimizations():
    """æµ‹è¯•æ‰€æœ‰ä¼˜åŒ–"""
    print("=== æµ‹è¯•æ‰€æœ‰ä¼˜åŒ– ===")
    
    # æµ‹è¯•ä¸åŒé…ç½®
    configs = [
        ("åŸºç¡€å¢å¼º", {"use_dynamic_attention": False, "use_multi_scale": False}),
        ("åŠ¨æ€æ³¨æ„åŠ›", {"use_dynamic_attention": True, "use_multi_scale": False}),
        ("å¤šå°ºåº¦FPN", {"use_dynamic_attention": False, "use_multi_scale": True}),
        ("å…¨åŠŸèƒ½", {"use_dynamic_attention": True, "use_multi_scale": True}),
    ]
    
    x = torch.randn(2, 3, 224, 224)
    
    for name, config in configs:
        model = create_starlite_model(
            enhanced=True,
            use_attention=True,
            use_fpn=True,
            **config
        )
        
        with torch.no_grad():
            output = model(x)
        
        param_count = sum(p.numel() for p in model.parameters())
        print(f"{name}: è¾“å‡ºå½¢çŠ¶ {output.shape}, å‚æ•°æ•°é‡ {param_count:,}")

def test_quantization_fusion():
    """æµ‹è¯•é‡åŒ–èåˆ"""
    print("\n=== æµ‹è¯•é‡åŒ–èåˆ ===")
    
    # æµ‹è¯•å…¨åŠŸèƒ½æ¨¡å‹
    model = create_starlite_model(
        enhanced=True,
        use_attention=True,
        use_fpn=True,
        use_dynamic_attention=True,
        use_multi_scale=True
    )
    
    # æ£€æŸ¥æ¨¡å‹ç»“æ„
    print("èåˆå‰çš„æ¨¡å‹ç»“æ„:")
    print(f"æ³¨æ„åŠ›å±‚æ•°é‡: {len(model.model.attention_layers) if hasattr(model.model, 'attention_layers') else 0}")
    print(f"FPNå±‚æ•°é‡: {len(model.model.fpn) if hasattr(model.model, 'fpn') else 0}")
    
    # å°è¯•èåˆ
    try:
        model.fuse_model()
        print("âœ… é‡åŒ–èåˆæˆåŠŸ")
    except Exception as e:
        print(f"âŒ é‡åŒ–èåˆå¤±è´¥: {e}")
        return False
    
    # èåˆåæµ‹è¯•å‰å‘ä¼ æ’­
    x = torch.randn(1, 3, 224, 224)
    with torch.no_grad():
        output = model(x)
    
    print(f"èåˆåè¾“å‡ºå½¢çŠ¶: {output.shape}")
    print("âœ… é‡åŒ–èåˆæµ‹è¯•é€šè¿‡")
    return True

def test_layernorm_in_classifier():
    """æµ‹è¯•åˆ†ç±»å¤´ä¸­çš„LayerNorm"""
    print("\n=== æµ‹è¯•åˆ†ç±»å¤´LayerNorm ===")
    
    model = create_starlite_model(enhanced=True, use_attention=True, use_fpn=True)
    
    # æ£€æŸ¥åˆ†ç±»å¤´ç»“æ„
    classifier = model.model.classifier
    print("åˆ†ç±»å¤´ç»“æ„:")
    for i, layer in enumerate(classifier):
        print(f"  {i}: {type(layer).__name__}")
    
    # æ£€æŸ¥æ˜¯å¦åŒ…å«LayerNorm
    has_layernorm = any(isinstance(layer, nn.LayerNorm) for layer in classifier)
    print(f"åŒ…å«LayerNorm: {has_layernorm}")
    
    if has_layernorm:
        print("âœ… LayerNormå·²åº”ç”¨")
    else:
        print("âŒ LayerNormæœªæ‰¾åˆ°")
    
    return has_layernorm

def test_fpn_implementation():
    """æµ‹è¯•FPNå®ç°"""
    print("\n=== æµ‹è¯•FPNå®ç° ===")
    
    model = create_starlite_model(enhanced=True, use_attention=True, use_fpn=True, use_multi_scale=True)
    
    # æ£€æŸ¥FPNå±‚ç»“æ„
    if hasattr(model.model, 'fpn'):
        print("FPNå±‚ç»“æ„:")
        for name, fpn_layer in model.model.fpn.items():
            print(f"  {name}: {type(fpn_layer).__name__}")
            
            # æ£€æŸ¥MultiScaleFPNçš„ç‰¹æ®Šç»“æ„
            if hasattr(fpn_layer, 'scale_layers'):
                print(f"    å¤šå°ºåº¦å±‚æ•°é‡: {len(fpn_layer.scale_layers)}")
                print(f"    èåˆå±‚: {type(fpn_layer.fusion_conv).__name__}")
    
    print("âœ… FPNå®ç°æ£€æŸ¥å®Œæˆ")

def test_weight_loading_logic():
    """æµ‹è¯•æƒé‡åŠ è½½é€»è¾‘"""
    print("\n=== æµ‹è¯•æƒé‡åŠ è½½é€»è¾‘ ===")
    
    # æµ‹è¯•ä¸åŒé…ç½®çš„æƒé‡åŠ è½½
    configs = [
        ("åŸå§‹æ¨¡å‹", {"enhanced": False}),
        ("å¢å¼ºæ¨¡å‹", {"enhanced": True}),
    ]
    
    for name, config in configs:
        try:
            model = create_starlite_model(pretrained=False, **config)
            print(f"{name}: åˆ›å»ºæˆåŠŸ")
        except Exception as e:
            print(f"{name}: åˆ›å»ºå¤±è´¥ - {e}")
    
    print("âœ… æƒé‡åŠ è½½é€»è¾‘æµ‹è¯•å®Œæˆ")

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("å¼€å§‹æµ‹è¯•æ‰€æœ‰ä¼˜åŒ–...")
    
    try:
        test_optimizations()
        test_quantization_fusion()
        test_layernorm_in_classifier()
        test_fpn_implementation()
        test_weight_loading_logic()
        
        print("\nğŸ‰ æ‰€æœ‰ä¼˜åŒ–æµ‹è¯•é€šè¿‡ï¼")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 