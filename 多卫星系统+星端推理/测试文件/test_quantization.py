#!/usr/bin/env python3
"""
æµ‹è¯•é‡åŒ–åŠŸèƒ½çš„è„šæœ¬
"""

import os
import sys
import torch
import subprocess

def test_quantization():
    print("="*60)
    print("å¼€å§‹æµ‹è¯•é‡åŒ–åŠŸèƒ½...")
    print("="*60)
    
    # æ£€æŸ¥å¿…è¦æ–‡ä»¶
    required_files = [
        "inference/quantize_model.py",
        "train_model.py"
    ]
    
    for file_path in required_files:
        if not os.path.exists(file_path):
            print(f"âŒ ç¼ºå°‘å¿…è¦æ–‡ä»¶: {file_path}")
            return False
        else:
            print(f"âœ… æ‰¾åˆ°æ–‡ä»¶: {file_path}")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰è®­ç»ƒå¥½çš„æ¨¡å‹
    model_paths = [
        "models/best_multimodal_patch_model.pth",
        "models/checkpoint.pth"
    ]
    
    model_found = False
    for model_path in model_paths:
        if os.path.exists(model_path):
            print(f"âœ… æ‰¾åˆ°æ¨¡å‹æ–‡ä»¶: {model_path}")
            model_found = True
            break
    
    if not model_found:
        print("âŒ æœªæ‰¾åˆ°è®­ç»ƒå¥½çš„æ¨¡å‹æ–‡ä»¶")
        print("è¯·å…ˆè¿è¡Œè®­ç»ƒè„šæœ¬ç”Ÿæˆæ¨¡å‹")
        return False
    
    # æµ‹è¯•é‡åŒ–è„šæœ¬
    print("\nå¼€å§‹æµ‹è¯•é‡åŒ–è„šæœ¬...")
    try:
        cmd = [
            sys.executable, "inference/quantize_model.py",
            "--model_path", model_paths[0] if os.path.exists(model_paths[0]) else model_paths[1],
            "--quant_path", "models/test_quantized_model.pt"
        ]
        
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)
        
        if result.returncode == 0:
            print("âœ… é‡åŒ–è„šæœ¬æ‰§è¡ŒæˆåŠŸ")
            print("é‡åŒ–è¾“å‡º:")
            print(result.stdout)
            
            # æ£€æŸ¥é‡åŒ–æ¨¡å‹æ–‡ä»¶
            if os.path.exists("models/test_quantized_model.pt"):
                file_size = os.path.getsize("models/test_quantized_model.pt") / (1024 * 1024)
                print(f"âœ… é‡åŒ–æ¨¡å‹æ–‡ä»¶ç”ŸæˆæˆåŠŸï¼Œå¤§å°: {file_size:.2f} MB")
                
                # æµ‹è¯•åŠ è½½é‡åŒ–æ¨¡å‹
                try:
                    quantized_model = torch.jit.load("models/test_quantized_model.pt")
                    dummy_image = torch.randn(1, 3, 256, 256)
                    dummy_sim_feat = torch.randn(1, 11)
                    
                    with torch.no_grad():
                        output = quantized_model(dummy_image, dummy_sim_feat)
                    
                    print(f"âœ… é‡åŒ–æ¨¡å‹æ¨ç†æµ‹è¯•é€šè¿‡ï¼Œè¾“å‡ºå½¢çŠ¶: {output.shape}")
                    return True
                    
                except Exception as e:
                    print(f"âŒ é‡åŒ–æ¨¡å‹æ¨ç†æµ‹è¯•å¤±è´¥: {e}")
                    return False
            else:
                print("âŒ é‡åŒ–æ¨¡å‹æ–‡ä»¶æœªç”Ÿæˆ")
                return False
        else:
            print("âŒ é‡åŒ–è„šæœ¬æ‰§è¡Œå¤±è´¥")
            print("é”™è¯¯è¾“å‡º:")
            print(result.stderr)
            return False
            
    except subprocess.TimeoutExpired:
        print("âŒ é‡åŒ–è„šæœ¬æ‰§è¡Œè¶…æ—¶")
        return False
    except Exception as e:
        print(f"âŒ é‡åŒ–è„šæœ¬æ‰§è¡Œå¼‚å¸¸: {e}")
        return False

def test_training_quantization_integration():
    print("\n" + "="*60)
    print("æµ‹è¯•è®­ç»ƒè„šæœ¬ä¸­çš„é‡åŒ–é›†æˆ...")
    print("="*60)
    
    # æ£€æŸ¥è®­ç»ƒè„šæœ¬ä¸­æ˜¯å¦åŒ…å«é‡åŒ–ä»£ç 
    try:
        with open("train_model.py", "r", encoding="utf-8") as f:
            content = f.read()
            
        if "è‡ªåŠ¨é‡åŒ–" in content and "quantize_model.py" in content:
            print("âœ… è®­ç»ƒè„šæœ¬åŒ…å«é‡åŒ–é›†æˆä»£ç ")
            return True
        else:
            print("âŒ è®­ç»ƒè„šæœ¬ç¼ºå°‘é‡åŒ–é›†æˆä»£ç ")
            return False
            
    except Exception as e:
        print(f"âŒ è¯»å–è®­ç»ƒè„šæœ¬å¤±è´¥: {e}")
        return False

if __name__ == "__main__":
    print("é‡åŒ–åŠŸèƒ½æµ‹è¯•")
    print("="*60)
    
    # æµ‹è¯•é‡åŒ–è„šæœ¬
    quantization_ok = test_quantization()
    
    # æµ‹è¯•è®­ç»ƒé›†æˆ
    integration_ok = test_training_quantization_integration()
    
    print("\n" + "="*60)
    print("æµ‹è¯•ç»“æœæ€»ç»“:")
    print(f"é‡åŒ–è„šæœ¬æµ‹è¯•: {'âœ… é€šè¿‡' if quantization_ok else 'âŒ å¤±è´¥'}")
    print(f"è®­ç»ƒé›†æˆæµ‹è¯•: {'âœ… é€šè¿‡' if integration_ok else 'âŒ å¤±è´¥'}")
    
    if quantization_ok and integration_ok:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼é‡åŒ–åŠŸèƒ½å·²å‡†å¤‡å°±ç»ª")
        print("è®­ç»ƒå®Œæˆåå°†è‡ªåŠ¨è¿›è¡Œæ¨¡å‹é‡åŒ–")
    else:
        print("\nâš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç›¸å…³é…ç½®")
    print("="*60) 