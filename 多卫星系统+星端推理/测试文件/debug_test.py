import torch
import sys
import os

# æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.abspath('.'))

def debug_model_loading():
    print("=== è¯¦ç»†è°ƒè¯•æ¨¡å‹åŠ è½½ ===")
    
    try:
        from run_inference import load_deeplab_model
        device = torch.device("cpu")
        
        print("1. å¼€å§‹åŠ è½½æ¨¡å‹...")
        model = load_deeplab_model("models/seg_model.pth", device)
        print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ!")
        
        print("\n2. æµ‹è¯•å‰å‘ä¼ æ’­...")
        batch_size = 1
        img = torch.randn(batch_size, 3, 256, 256)
        sim_feat = torch.randn(batch_size, 11)
        
        print(f"è¾“å…¥å›¾åƒå½¢çŠ¶: {img.shape}")
        print(f"ä»¿çœŸç‰¹å¾å½¢çŠ¶: {sim_feat.shape}")
        
        with torch.no_grad():
            output = model(img, sim_feat)
            print(f"âœ… å‰å‘ä¼ æ’­æˆåŠŸ! è¾“å‡ºå½¢çŠ¶: {output.shape}")
        
        print("\n3. æµ‹è¯•æ¨ç†è„šæœ¬çš„å…¶ä»–åŠŸèƒ½...")
        from run_inference import load_image, infer_and_time
        
        # æµ‹è¯•å›¾åƒåŠ è½½
        print("æµ‹è¯•å›¾åƒåŠ è½½...")
        test_img_path = "data/combined_dataset/images/tier3/"
        import glob
        img_files = glob.glob(os.path.join(test_img_path, "*.png")) + glob.glob(os.path.join(test_img_path, "*.jpg"))
        if img_files:
            test_img = load_image(img_files[0])
            print(f"âœ… å›¾åƒåŠ è½½æˆåŠŸ! å½¢çŠ¶: {test_img.shape}")
            
            # æµ‹è¯•æ¨ç†å’Œè®¡æ—¶
            print("æµ‹è¯•æ¨ç†å’Œè®¡æ—¶...")
            avg_time, min_time, max_time, pred_mask = infer_and_time(model, test_img, "original", sim_feat)
            print(f"âœ… æ¨ç†æˆåŠŸ! å¹³å‡æ—¶é—´: {avg_time:.2f} ms")
            print(f"é¢„æµ‹æ©ç å½¢çŠ¶: {pred_mask.shape}")
        else:
            print("âŒ æœªæ‰¾åˆ°æµ‹è¯•å›¾åƒ")
        
        return True
        
    except Exception as e:
        print(f"âŒ è°ƒè¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = debug_model_loading()
    if success:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•éƒ½é€šè¿‡äº†!")
    else:
        print("\nğŸ’¥ è¿˜æœ‰é—®é¢˜éœ€è¦è§£å†³ã€‚") 