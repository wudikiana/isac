import torch
import numpy as np
import os
import sys
sys.path.insert(0, os.path.abspath('.'))
from train_model import DeepLabWithSimFeature
from inference.run_inference import load_image, load_deeplab_model

def test_model_output():
    """æµ‹è¯•æ¨¡å‹è¾“å‡ºæ˜¯å¦æ­£å¸¸"""
    print("ğŸ” æµ‹è¯•æ¨¡å‹è¾“å‡º...")
    
    # åˆ›å»ºæµ‹è¯•å›¾åƒ
    test_img = torch.randn(1, 3, 256, 256)  # æ¨¡æ‹Ÿå½’ä¸€åŒ–åçš„å›¾åƒ
    test_sim_feats = torch.randn(1, 11)     # æ¨¡æ‹Ÿä»¿çœŸç‰¹å¾
    
    # åˆ›å»ºæ¨¡å‹
    model = DeepLabWithSimFeature(in_channels=3, num_classes=1, sim_feat_dim=11)
    model.eval()
    
    with torch.no_grad():
        output = model(test_img, test_sim_feats)
        
    print(f"æ¨¡å‹è¾“å‡ºå½¢çŠ¶: {output.shape}")
    print(f"è¾“å‡ºèŒƒå›´: [{output.min().item():.3f}, {output.max().item():.3f}]")
    print(f"è¾“å‡ºå‡å€¼: {output.mean().item():.3f}")
    print(f"è¾“å‡ºæ ‡å‡†å·®: {output.std().item():.3f}")
    
    # åº”ç”¨sigmoid
    output_sigmoid = torch.sigmoid(output)
    print(f"SigmoidåèŒƒå›´: [{output_sigmoid.min().item():.3f}, {output_sigmoid.max().item():.3f}]")
    print(f"Sigmoidåå‡å€¼: {output_sigmoid.mean().item():.3f}")
    
    return output

def test_image_loading():
    """æµ‹è¯•å›¾åƒåŠ è½½å’Œé¢„å¤„ç†"""
    print("\nğŸ–¼ï¸ æµ‹è¯•å›¾åƒåŠ è½½...")
    
    # æŸ¥æ‰¾æµ‹è¯•å›¾åƒ
    test_image_path = None
    possible_paths = [
        "data/combined_dataset/images/train2017/guatemala-volcano_00000000_post_disaster.png",
        "data/combined_dataset/images/val2017/guatemala-volcano_00000004_post_disaster.png",
        "data/combined_dataset/images/test2017/guatemala-volcano_00000003_post_disaster.png"
    ]
    
    for path in possible_paths:
        if os.path.exists(path):
            test_image_path = path
            break
    
    if test_image_path is None:
        print("âŒ æœªæ‰¾åˆ°æµ‹è¯•å›¾åƒï¼Œè·³è¿‡å›¾åƒåŠ è½½æµ‹è¯•")
        return None
    
    print(f"ä½¿ç”¨æµ‹è¯•å›¾åƒ: {test_image_path}")
    
    # åŠ è½½å›¾åƒ
    img = load_image(test_image_path)
    print(f"åŠ è½½åå›¾åƒå½¢çŠ¶: {img.shape}")
    print(f"å›¾åƒèŒƒå›´: [{img.min().item():.3f}, {img.max().item():.3f}]")
    print(f"å›¾åƒå‡å€¼: {img.mean().item():.3f}")
    print(f"å›¾åƒæ ‡å‡†å·®: {img.std().item():.3f}")
    
    return img

def test_model_inference():
    """æµ‹è¯•å®Œæ•´çš„æ¨¡å‹æ¨ç†"""
    print("\nğŸš€ æµ‹è¯•å®Œæ•´æ¨ç†...")
    
    # åŠ è½½æµ‹è¯•å›¾åƒ
    img = test_image_loading()
    if img is None:
        print("âŒ æ— æ³•åŠ è½½æµ‹è¯•å›¾åƒï¼Œè·³è¿‡æ¨ç†æµ‹è¯•")
        return
    
    # åˆ›å»ºæ¨¡å‹
    model = DeepLabWithSimFeature(in_channels=3, num_classes=1, sim_feat_dim=11)
    model.eval()
    
    # åˆ›å»ºä»¿çœŸç‰¹å¾
    sim_feats = torch.randn(1, 11)
    
    with torch.no_grad():
        output = model(img, sim_feats)
        
    print(f"æ¨ç†è¾“å‡ºå½¢çŠ¶: {output.shape}")
    print(f"æ¨ç†è¾“å‡ºèŒƒå›´: [{output.min().item():.3f}, {output.max().item():.3f}]")
    print(f"æ¨ç†è¾“å‡ºå‡å€¼: {output.mean().item():.3f}")
    
    # åº”ç”¨sigmoid
    output_sigmoid = torch.sigmoid(output)
    print(f"SigmoidåèŒƒå›´: [{output_sigmoid.min().item():.3f}, {output_sigmoid.max().item():.3f}]")
    print(f"Sigmoidåå‡å€¼: {output_sigmoid.mean().item():.3f}")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰åˆç†çš„é¢„æµ‹
    pred_mask = output_sigmoid.squeeze().numpy()
    high_conf_pixels = (pred_mask > 0.5).sum()
    total_pixels = pred_mask.size
    print(f"é«˜ç½®ä¿¡åº¦åƒç´ æ•°: {high_conf_pixels}/{total_pixels} ({high_conf_pixels/total_pixels:.2%})")
    
    return output_sigmoid

def test_data_consistency():
    """æµ‹è¯•æ•°æ®ä¸€è‡´æ€§"""
    print("\nğŸ“Š æµ‹è¯•æ•°æ®ä¸€è‡´æ€§...")
    
    from data_utils.data_loader import get_multimodal_patch_dataloaders
    
    try:
        train_loader, val_loader = get_multimodal_patch_dataloaders(
            data_root="data/patch_dataset",
            sim_feature_csv="data/sim_features.csv",
            batch_size=2,
            num_workers=0,  # é¿å…å¤šè¿›ç¨‹é—®é¢˜
            damage_boost=1
        )
        
        # è·å–ä¸€ä¸ªbatch
        for batch_idx, (images, masks, sim_feats) in enumerate(train_loader):
            if batch_idx >= 1:  # åªæµ‹è¯•ç¬¬ä¸€ä¸ªbatch
                break
                
            print(f"è®­ç»ƒæ•°æ®å½¢çŠ¶:")
            print(f"  å›¾åƒ: {images.shape}")
            print(f"  æ©ç : {masks.shape}")
            print(f"  ä»¿çœŸç‰¹å¾: {sim_feats.shape}")
            print(f"å›¾åƒèŒƒå›´: [{images.min().item():.3f}, {images.max().item():.3f}]")
            print(f"å›¾åƒå‡å€¼: {images.mean().item():.3f}")
            print(f"å›¾åƒæ ‡å‡†å·®: {images.std().item():.3f}")
            print(f"æ©ç èŒƒå›´: [{masks.min().item():.3f}, {masks.max().item():.3f}]")
            print(f"ä»¿çœŸç‰¹å¾èŒƒå›´: [{sim_feats.min().item():.3f}, {sim_feats.max().item():.3f}]")
            
            # æµ‹è¯•æ¨¡å‹æ¨ç†
            model = DeepLabWithSimFeature(in_channels=3, num_classes=1, sim_feat_dim=11)
            model.eval()
            
            with torch.no_grad():
                outputs = model(images, sim_feats)
                
            print(f"æ¨¡å‹è¾“å‡ºå½¢çŠ¶: {outputs.shape}")
            print(f"æ¨¡å‹è¾“å‡ºèŒƒå›´: [{outputs.min().item():.3f}, {outputs.max().item():.3f}]")
            print(f"æ¨¡å‹è¾“å‡ºå‡å€¼: {outputs.mean().item():.3f}")
            
            # åº”ç”¨sigmoid
            outputs_sigmoid = torch.sigmoid(outputs)
            print(f"SigmoidåèŒƒå›´: [{outputs_sigmoid.min().item():.3f}, {outputs_sigmoid.max().item():.3f}]")
            print(f"Sigmoidåå‡å€¼: {outputs_sigmoid.mean().item():.3f}")
            
            break
            
    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½æµ‹è¯•å¤±è´¥: {e}")

if __name__ == "__main__":
    print("ğŸ§ª å¼€å§‹æ¨ç†ä¿®å¤æµ‹è¯•...")
    print("="*50)
    
    # æµ‹è¯•1: æ¨¡å‹è¾“å‡º
    test_model_output()
    
    # æµ‹è¯•2: å›¾åƒåŠ è½½
    test_image_loading()
    
    # æµ‹è¯•3: å®Œæ•´æ¨ç†
    test_model_inference()
    
    # æµ‹è¯•4: æ•°æ®ä¸€è‡´æ€§
    test_data_consistency()
    
    print("\n" + "="*50)
    print("âœ… æ¨ç†ä¿®å¤æµ‹è¯•å®Œæˆï¼") 