#!/usr/bin/env python3
"""
ç®€å•çš„CPU-GPUååŒä¼˜åŒ–æ€§èƒ½æµ‹è¯•
"""

import torch
import time
import numpy as np

def test_standard_training():
    """æµ‹è¯•æ ‡å‡†è®­ç»ƒæ€§èƒ½"""
    print("ğŸ§ª æµ‹è¯•æ ‡å‡†è®­ç»ƒæ€§èƒ½...")
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = torch.nn.Sequential(
        torch.nn.Conv2d(3, 16, 3, padding=1),
        torch.nn.ReLU(),
        torch.nn.Conv2d(16, 1, 1)
    ).to(device)
    
    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)
    scaler = torch.cuda.amp.GradScaler()
    
    batch_size = 8
    images = torch.randn(batch_size, 3, 64, 64).to(device)
    masks = torch.randint(0, 2, (batch_size, 1, 64, 64)).float().to(device)
    
    # é¢„çƒ­
    for _ in range(3):
        optimizer.zero_grad()
        with torch.cuda.amp.autocast():
            outputs = model(images)
            loss = torch.nn.functional.binary_cross_entropy_with_logits(outputs, masks)
        scaler.scale(loss).backward()
        scaler.step(optimizer)
        scaler.update()
    
    # æ€§èƒ½æµ‹è¯•
    torch.cuda.synchronize()
    start_time = time.time()
    
    for i in range(20):
        optimizer.zero_grad()
        with torch.cuda.amp.autocast():
            outputs = model(images)
            loss = torch.nn.functional.binary_cross_entropy_with_logits(outputs, masks)
        scaler.scale(loss).backward()
        scaler.step(optimizer)
        scaler.update()
    
    torch.cuda.synchronize()
    std_time = time.time() - start_time
    
    print(f"âœ… æ ‡å‡†è®­ç»ƒå®Œæˆ: {std_time:.3f}ç§’ (20æ­¥)")
    return std_time

def test_cpu_assisted_training():
    """æµ‹è¯•CPUè¾…åŠ©è®­ç»ƒæ€§èƒ½"""
    print("ğŸ§ª æµ‹è¯•CPUè¾…åŠ©è®­ç»ƒæ€§èƒ½...")
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # åˆ›å»ºä¸€ä¸ªå…¼å®¹çš„æµ‹è¯•æ¨¡å‹
    class TestModel(torch.nn.Module):
        def __init__(self):
            super().__init__()
            self.conv1 = torch.nn.Conv2d(3, 16, 3, padding=1)
            self.relu = torch.nn.ReLU()
            self.conv2 = torch.nn.Conv2d(16, 1, 1)
        
        def forward(self, img, sim_feat):
            # å¿½ç•¥sim_featï¼Œåªå¤„ç†å›¾åƒ
            x = self.conv1(img)
            x = self.relu(x)
            x = self.conv2(x)
            return x
    
    model = TestModel().to(device)
    
    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)
    
    # å¯¼å…¥æ··åˆç²¾åº¦è®­ç»ƒå™¨
    try:
        from train_model import HybridPrecisionTrainer
        hybrid_trainer = HybridPrecisionTrainer(model, optimizer, device)
        
        batch_size = 8
        images = torch.randn(batch_size, 3, 64, 64).to(device)
        masks = torch.randint(0, 2, (batch_size, 1, 64, 64)).float().to(device)
        sim_feats = torch.randn(batch_size, 11).to(device)
        
        # é¢„çƒ­
        for _ in range(3):
            loss, outputs = hybrid_trainer.train_step(images, masks, sim_feats)
        
        # æ€§èƒ½æµ‹è¯•
        torch.cuda.synchronize()
        start_time = time.time()
        
        for i in range(20):
            loss, outputs = hybrid_trainer.train_step(images, masks, sim_feats)
        
        torch.cuda.synchronize()
        hybrid_time = time.time() - start_time
        
        # è·å–æ€§èƒ½ç»Ÿè®¡
        stats = hybrid_trainer.get_performance_stats()
        
        print(f"âœ… CPUè¾…åŠ©è®­ç»ƒå®Œæˆ: {hybrid_time:.3f}ç§’ (20æ­¥)")
        
        if stats:
            print(f"  GPUåˆ©ç”¨ç‡: {stats['gpu_utilization']:.1f}%")
            print(f"  CPUåˆ†æ‹…æ¯”ä¾‹: {100-stats['gpu_utilization']:.1f}%")
        
        hybrid_trainer.shutdown()
        return hybrid_time, stats
        
    except Exception as e:
        print(f"âŒ CPUè¾…åŠ©è®­ç»ƒæµ‹è¯•å¤±è´¥: {e}")
        return None, None

def main():
    print("="*60)
    print("ğŸš€ CPU-GPUååŒä¼˜åŒ–æ€§èƒ½æµ‹è¯•")
    print("="*60)
    
    # æµ‹è¯•æ ‡å‡†è®­ç»ƒ
    std_time = test_standard_training()
    
    # æµ‹è¯•CPUè¾…åŠ©è®­ç»ƒ
    result = test_cpu_assisted_training()
    if result[0] is not None:
        hybrid_time, stats = result
        
        # æ€§èƒ½å¯¹æ¯”
        print(f"\nğŸ“Š æ€§èƒ½å¯¹æ¯”ç»“æœ:")
        print(f"  æ ‡å‡†è®­ç»ƒæ—¶é—´: {std_time:.3f}ç§’")
        print(f"  CPUè¾…åŠ©è®­ç»ƒæ—¶é—´: {hybrid_time:.3f}ç§’")
        print(f"  æ€§èƒ½æå‡: {std_time/hybrid_time:.2f}x")
        
        if stats:
            print(f"  GPUåˆ©ç”¨ç‡: {stats['gpu_utilization']:.1f}%")
            print(f"  CPUåˆ†æ‹…æ¯”ä¾‹: {100-stats['gpu_utilization']:.1f}%")
        
        print("\nğŸ‰ CPU-GPUååŒä¼˜åŒ–æµ‹è¯•å®Œæˆï¼")
    else:
        print("\nâŒ CPUè¾…åŠ©è®­ç»ƒæµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä»£ç ")

if __name__ == "__main__":
    main()
